# KPI Red Recovery - M√≥dulo de Drenaje del Backlog

## üìã PROP√ìSITO

Este m√≥dulo est√° dise√±ado para **drenar espec√≠ficamente el backlog del KPI rojo** ("Leads sin identidad ni claims"), procesando PRIORITARIAMENTE los leads que el KPI rojo cuenta como "sin identidad ni claims".

## ‚ö†Ô∏è DIFERENCIAS CR√çTICAS

### "Matched last 24h" ‚â† "Drenado del KPI rojo"

**IMPORTANTE:** El m√≥dulo "Matched last 24h" (`ops.identity_matching_jobs`) y el m√≥dulo "KPI Red Recovery" (`ops.cabinet_kpi_red_recovery_queue`) son **DIFERENTES**:

- **"Matched last 24h"**: Cuenta TODOS los matches de identidad en las √∫ltimas 24 horas, independientemente de si estaban en el KPI rojo o no.
- **"KPI Red Recovery"**: Procesa ESPEC√çFICAMENTE los leads que est√°n en el KPI rojo y los drena del backlog.

**El √∫nico KPI de √©xito del recovery dirigido es:**
- `matched_out > new_backlog_in` (m√°s leads recuperados que nuevos leads entrando)
- Y/O `backlog_end < backlog_start` (backlog disminuye)

## üéØ CRITERIOS DE √âXITO

### √âxito del Recovery Dirigido

El sistema tiene √©xito cuando:
1. **Backlog disminuye**: `backlog_end < backlog_start`
2. **Throughput positivo**: `matched_out > new_backlog_in`
3. **Leads matched NO est√°n en backlog**: 0% de leads matched aparecen en `ops.v_cabinet_kpi_red_backlog`

### Si el KPI rojo NO baja

**El sistema NO est√° fallando.** El sistema est√° explicando por qu√© no puede bajar:

1. **Falta de datos**: `fail_reason = 'missing_identifiers'` o `'no_match_found'`
   - Los leads no tienen phone/doc/email suficientes para matching
   - **Soluci√≥n**: Mejorar calidad de datos en origen

2. **Conflictos**: `fail_reason = 'conflict_multiple_candidates'`
   - Se encontraron m√∫ltiples candidatos con scores muy cercanos
   - **Soluci√≥n**: Revisi√≥n manual o ajustar reglas de matching

3. **Backlog entrante mayor**: `new_backlog_in > matched_out`
   - Entran m√°s leads nuevos al backlog de los que se recuperan
   - **Soluci√≥n**: Aumentar frecuencia del job o capacidad de procesamiento

## üèóÔ∏è ARQUITECTURA

### Componentes

1. **Vista de Backlog**: `ops.v_cabinet_kpi_red_backlog`
   - Define el set exacto de leads en el KPI rojo
   - Source of truth para el backlog

2. **Tabla de Cola**: `ops.cabinet_kpi_red_recovery_queue`
   - Cola de trabajo para procesar leads del backlog
   - Estados: `pending`, `matched`, `failed`

3. **Job Seed**: `backend/jobs/seed_kpi_red_queue.py`
   - Sembrar la cola desde el backlog
   - Ejecutar cada hora/d√≠a

4. **Job Recovery**: `backend/jobs/recover_kpi_red_leads.py`
   - Procesar leads pending de la cola
   - Intentar matching y crear links/origin
   - Ejecutar cada 1-4 horas

5. **Vista de M√©tricas**: `ops.v_cabinet_kpi_red_recovery_metrics_daily`
   - M√©tricas diarias de recovery
   - Backlog, throughput, net change

6. **Endpoint**: `GET /api/v1/ops/payments/cabinet-financial-14d/kpi-red-recovery-metrics`
   - Exponer m√©tricas de recovery

## üîß CONSISTENCIA DE source_pk

**CR√çTICO:** Todos los `source_pk` usan el mismo formato:

```sql
COALESCE(external_id::text, id::text)
```

Este formato se usa en:
- `ops.v_cabinet_kpi_red_backlog.lead_source_pk`
- `ops.cabinet_kpi_red_recovery_queue.lead_source_pk`
- `canon.identity_links.source_pk` (cuando `source_table = 'module_ct_cabinet_leads'`)

**Verificaci√≥n:** Ejecutar `backend/scripts/verify_source_pk_consistency.py`

## üîí GUARDRAIL

### Verificaci√≥n Autom√°tica

Ejecutar peri√≥dicamente:
```bash
python -m scripts.verify_kpi_red_drain
```

Este script verifica que:
- 0% de leads matched (`status='matched'` en queue) aparecen en el backlog
- Si alg√∫n lead matched est√° en el backlog ‚Üí `exit(1)` (fallo cr√≠tico)

**Causas comunes de fallo:**
1. `source_pk` mismatch (casting diferente)
2. `identity_link` no se cre√≥ correctamente
3. Vista del backlog no sincronizada
4. Race condition (lead matched despu√©s de snapshot)

## üìä M√âTRICAS

### M√©tricas Diarias

- **backlog_start**: Backlog al inicio del d√≠a
- **new_backlog_in**: Leads que entraron al backlog en este d√≠a
- **matched_out**: Leads que fueron matched (salieron del backlog) en este d√≠a
- **backlog_end**: Backlog al final del d√≠a (`backlog_start + new_backlog_in - matched_out`)
- **net_change**: Cambio neto (`new_backlog_in - matched_out`)
- **top_fail_reason**: Raz√≥n de fallo m√°s com√∫n

### Interpretaci√≥n

- **net_change > 0**: Entran m√°s leads de los que se recuperan (backlog crece)
- **net_change < 0**: Se recuperan m√°s leads de los que entran (backlog disminuye)
- **net_change = 0**: Balance (backlog estable)

## üöÄ EJECUCI√ìN

### Primera Vez

1. **Ejecutar migraci√≥n:**
   ```bash
   cd backend
   alembic upgrade head
   ```

2. **Crear vistas SQL:**
   ```bash
   psql -d <database> -f backend/sql/ops/v_cabinet_kpi_red_backlog.sql
   psql -d <database> -f backend/sql/ops/v_cabinet_kpi_red_recovery_metrics_daily.sql
   ```

3. **Sembrar cola (primera vez):**
   ```bash
   python -m jobs.seed_kpi_red_queue
   ```

4. **Ejecutar recovery:**
   ```bash
   python -m jobs.recover_kpi_red_leads --limit 1000
   ```

### Operaci√≥n Continua

- **Job Seed**: Ejecutar cada hora/d√≠a (mantener cola sincronizada con backlog)
- **Job Recovery**: Ejecutar cada 1-4 horas (drenar backlog)
- **Guardrail**: Ejecutar peri√≥dicamente para verificar integridad

## ‚úÖ VALIDACI√ìN

### Validaci√≥n de Impacto Real

Ejecutar:
```bash
python -m scripts.validate_kpi_red_impact --limit 1000
```

Este script:
1. Obtiene backlog ANTES
2. Ejecuta seed
3. Ejecuta recovery
4. Obtiene backlog DESPU√âS
5. Reporta diferencia y razones de fallo

### Verificaciones de Producci√≥n

Antes de mergear, ejecutar:

1. **Alembic heads:**
   ```bash
   alembic heads
   ```
   Debe retornar 1 solo head

2. **Consistencia source_pk:**
   ```bash
   python -m scripts.verify_source_pk_consistency
   ```

3. **Identity origin creation:**
   ```bash
   python -m scripts.verify_identity_origin_creation
   ```

4. **Guardrail:**
   ```bash
   python -m scripts.verify_kpi_red_drain
   ```

## üìù NOTAS

- El sistema es **idempotente**: puede ejecutarse m√∫ltiples veces sin romper
- Los jobs procesan en **batches** (500-1000 leads por batch)
- El job seed puede ejecutarse frecuentemente sin problemas (upsert idempotente)
- El job recovery debe ejecutarse peri√≥dicamente para drenar el backlog
- **ORIGIN_MISSING se corrige autom√°ticamente**: cuando hay link, se crea origin
